{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"INM706, Transformers","provenance":[],"collapsed_sections":["WI2WhEyk6P9Y"],"mount_file_id":"1ai_zXoIxwu3RkKx6EW05vhJ8wokJa9_o","authorship_tag":"ABX9TyMaP5uTGRhGdT6b/ylmtXuS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"F3Fq4V5cCLky","colab_type":"code","colab":{}},"source":["import re, os, sys\n","import  math, copy\n","import pickle\n","import numpy as np\n","import unicodedata\n","from matplotlib import pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","from torch.utils import data\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.nn.modules.normalization import LayerNorm\n","from torch.distributions.categorical import Categorical\n","#from torch.utils.tensorboard import SummaryWriter\n","#%load_ext tensorboard"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5lyz2bUoGT-","colab_type":"code","colab":{}},"source":["sys.path.append('/content/drive/My Drive/706')\n","import dataset_vf1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FmNxRLIPPjwc","colab_type":"text"},"source":["# Load pre-processed data"]},{"cell_type":"code","metadata":{"id":"d9VTvMUDqlUA","colab_type":"code","colab":{}},"source":["voc = pickle.load(open('/content/drive/My Drive/706/data_objects/voc.pkl', 'rb'))\n","pairs = pickle.load(open('/content/drive/My Drive/706/data_objects/pairs.pkl', 'rb'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WI2WhEyk6P9Y","colab_type":"text"},"source":["## If pickle error: preprocess data online"]},{"cell_type":"code","metadata":{"id":"e0QFD79z6Vqx","colab_type":"code","colab":{}},"source":["corpus_name = 'Cornell Movie-Dialogs'\n","wd = os.getcwd()\n","datafile = os.path.join(wd, '706/data_objects/formatted_movie_lines.txt')\n","\n","# Special tokens\n","PAD_token = 0  # Enables padding all utterances to same length\n","SOS_token = 1  # Start-Of-Sentence token: added at the beginning of each utterance\n","EOS_token = 2  # End-Of-Sentence token: added at the end of each utterance\n","\n","\n","\n","class Voc:\n","\tdef __init__(self, name):\n","\t\tself.name = name\n","\t\tself.trimmed = False\n","\t\tself.word2index = {}\n","\t\tself.word2count = {}\n","\t\tself.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","\t\tself.num_words = 3  # SOS, EOS, PAD\n","\n","\tdef addSentence(self, sentence):\n","\t\tfor word in sentence.split(' '):\n","\t\t\tself.addWord(word)\n","\n","\tdef addWord(self, word):\n","\t\tif word not in self.word2index:\n","\t\t\tself.word2index[word] = self.num_words\n","\t\t\tself.word2count[word] = 1\n","\t\t\tself.index2word[self.num_words] = word\n","\t\t\tself.num_words += 1\n","\t\telse:\n","\t\t\tself.word2count[word] += 1\n","\n","\t# Remove irrelevant words (appearing less than arbitrary count threshold in data set)\n","\tdef trim(self, min_count):\n","\t\tif self.trimmed:\n","\t\t\treturn\n","\t\tself.trimmed = True\n","\n","\t\tkeep_words = []\n","\n","\t\tfor k, v in self.word2count.items():\n","\t\t\tif v >= min_count:\n","\t\t\t\tkeep_words.append(k)\n","\n","\t\tprint('keep_words {} / {} = {:.4f}'.format(\n","\t\t\tlen(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n","\t\t))\n","\n","\t\t# Reinitialize dictionaries\n","\t\tself.word2index = {}\n","\t\tself.word2count = {}\n","\t\tself.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","\t\tself.num_words = 3  # Count default tokens\n","\n","\t\tfor word in keep_words:\n","\t\t\tself.addWord(word)\n","\n","\n","# Max utterance length\n","MAX_LENGTH = 20\n","\n","\n","# encoding: from unicode to ASCII\n","def unicodeToAscii(s):\n","\treturn ''.join(\n","\t\tc for c in unicodedata.normalize('NFD', s)\n","\t\tif unicodedata.category(c) != 'Mn'\n","\t)\n","\n","\n","\n","def normalizeString(s):\n","\ts = unicodeToAscii(s.lower().strip())\n","\ts = re.sub(r\"([.!?])\", r\" \\1\", s)\n","\ts = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","\ts = re.sub(r\"\\s+\", r\" \", s).strip()\n","\treturn s\n","\n","\n","# Returns constructed Voc class and a list of lists, each one containing a pair of utterances (question - answer like)\n","def readVocs(datafile, corpus_name):\n","\t# print(\"Reading lines...\")\n","\tlines = open(datafile, encoding='utf-8'). \\\n","\t\tread().strip().split('\\n')\n","\tpairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n","\tvoc = Voc(corpus_name)\n","\treturn voc, pairs\n","\n","\n","# Returns True if both pair utterances are shorter than MAX_LENGTH\n","def filterPair(p):\n","\treturn len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n","\n","\n","# EXPLICA!\n","def filterPairs(pairs):\n","\treturn [pair for pair in pairs if filterPair(pair)]\n","\n","\n","# Returns a populated Voc and list of filtered (all utterances shorter than MAX_LENGTH) pairs\n","def loadPrepareData(corpus_name, datafile):\n","\t# print(\"Start preparing training data ...\")\n","\tvoc, pairs = readVocs(datafile, corpus_name)\n","\t# print(\"Read {!s} sentence pairs\".format(len(pairs)))\n","\tpairs = filterPairs(pairs)\n","\t# print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n","\t# print(\"Counting words...\")\n","\tfor pair in pairs:\n","\t\tvoc.addSentence(pair[0])\n","\t\tvoc.addSentence(pair[1])\n","\t# print(\"Counted words:\", voc.num_words)\n","\treturn voc, pairs\n","\n","\n","voc, pairs = loadPrepareData(corpus_name, datafile)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L7EXn4AWUNgS","colab_type":"text"},"source":["# Utils"]},{"cell_type":"markdown","metadata":{"id":"SJF2uSnKLuWI","colab_type":"text"},"source":["Clone Modules"]},{"cell_type":"code","metadata":{"id":"xkzpV-52L0r4","colab_type":"code","colab":{}},"source":["def get_clones(module, N):\n","  return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fjjQXUYwUw80","colab_type":"text"},"source":["Create masks for subsuquent target positions: e.g. [False, False, False] , [True, False, False], [True, True, False], [True, True, True]"]},{"cell_type":"code","metadata":{"id":"ci0IkqxvUcJB","colab_type":"code","colab":{}},"source":["def nopeak_mask(size):\n","  np_mask = np.triu(np.ones((1, size, size)), k = 1).astype('uint8')\n","  np_mask = torch.from_numpy(np_mask) == 0\n","  return np_mask"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7KW2c8mmUwRx","colab_type":"code","colab":{}},"source":["def create_masks(src, trg, device):\n","  src_mask = (src != 0).unsqueeze(-2)\n","  #src_mask = src_mask.to(device)\n","  if trg is not None:\n","    trg_mask = (trg != 0).unsqueeze(-2)\n","    trg_mask = trg_mask.to(device)\n","    size = trg.size(1)\n","    np_mask = nopeak_mask(size)\n","    np_mask = np_mask.to(device)\n","    trg_mask = trg_mask & np_mask\n","  else:\n","    trg_mask = None\n","  return src_mask, trg_mask"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HeWlCIZv60aX","colab_type":"text"},"source":["# Modules"]},{"cell_type":"markdown","metadata":{"id":"HDD5E2u_9dgq","colab_type":"text"},"source":["## Word Position Encoder"]},{"cell_type":"markdown","metadata":{"id":"WWFqokS7LsnX","colab_type":"text"},"source":["Positional Encoder"]},{"cell_type":"code","metadata":{"id":"1c-WoCYl-Nr3","colab_type":"code","colab":{}},"source":["class PositionalEncoder(nn.Module):\n","  def __init__(self, emb_dim, max_seq_len = 200, dropout = 0.1):\n","    super().__init__()\n","    self.emb_dim = emb_dim\n","    self.wpe = nn.Embedding(max_seq_len, emb_dim) #word position encoding\n","    self.dropout = nn.Dropout(dropout)\n","  \n","  def forward(self, x):\n","    pos_ids = torch.arange(0, x.size(1), device = device).unsqueeze(0)\n","    xpe = self.wpe(pos_ids)\n","    return xpe"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HS89QSFRIrgT","colab_type":"text"},"source":["## Multi-Head Attention"]},{"cell_type":"code","metadata":{"id":"eHd52FHnIuxY","colab_type":"code","colab":{}},"source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, n_heads, emb_dim, dim_k = None, dropout = 0.1):\n","    super().__init__()\n","    self.emb_dim = emb_dim\n","    self.dim_k = dim_k if dim_k else emb_dim // n_heads\n","    self.n_heads = n_heads\n","    self.q_linear = nn.Linear(emb_dim, self.dim_k*n_heads)\n","    self.k_linear = nn.Linear(emb_dim, self.dim_k*n_heads)\n","    self.v_linear = nn.Linear(emb_dim, self.dim_k*n_heads)\n","\n","    self.dropout = nn.Dropout(dropout)\n","    self.out = nn.Linear(self.dim_k*n_heads, emb_dim)\n","\n","  def attention(self, q, k, v, dim_k, mask = None, dropout = None):\n","    k = k.transpose(-2, -1) # prepare k's shape for matmul\n","    scores = torch.matmul(q, k) / math.sqrt(dim_k) # (batch_size, n_heads, seq_len, seq_len)\n","    if mask is not None:\n","      mask = mask.unsqueeze(1)\n","      scores = scores.masked_fill(mask == 0, -1e9)\n","    softscores = F.softmax(scores, dim = -1)\n","    if dropout is not None: softscores = dropout(softscores)\n","    output = torch.matmul(softscores, v) # (batch_size, n_heads, seq_len, dim_k)\n","    return output, scores\n","\n","  def forward(self, q, k, v, mask = None):\n","    batch_size = q.size(0)\n","    q = self.q_linear(q) # (batch_size, seq_len, emd_dim)\n","    k = self.k_linear(k) # (batch_size, seq_len, emb_dim)\n","    v = self.v_linear(v) # (batch_size, seq_len, emb_dim)\n","\n","    k = k.view(batch_size, -1, self.n_heads, self.dim_k) # (batch_size, seq_len, n_heads, dim_k)\n","    q = q.view(batch_size, -1, self.n_heads, self.dim_k) # (batch_size, seq_len, n_heads, dim_k)\n","    v = v.view(batch_size, -1, self.n_heads, self.dim_k) # (batch_size, seq_len, n_heads, dim_k)\n","\n","    k = k.transpose(1, 2) # (batch_size, n_heads, seq_len, dim_k)\n","    q = q.transpose(1, 2) # (batch_size, n_heads, seq_len, dim_k)\n","    v = v.transpose(1, 2) # (batch_size, n_heads, seq_len, dim_k)\n","\n","    attn, scores = self.attention(q, k, v, self.dim_k, mask, self.dropout)\n","    concat = attn.transpose(1, 2).contiguous().view(batch_size, -1, self.dim_k*self.n_heads) # (batch_size, seq_len, emb_dim)\n","    output = self.out(concat)\n","    return output, scores"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a7_KvGNNMsZB","colab_type":"text"},"source":["## Feed-Forward"]},{"cell_type":"code","metadata":{"id":"E1KY_-jFMuY-","colab_type":"code","colab":{}},"source":["class FeedForward(nn.Module):\n","  def __init__(self, emb_dim, ffwd_dim = 2048, dropout = 0.1):\n","    super().__init__()\n","    self.linear1 = nn.Linear(emb_dim, ffwd_dim)\n","    self.dropout = nn.Dropout(dropout)\n","    self.linear2 = nn.Linear(ffwd_dim, emb_dim)\n","\n","  def forward(self, x):\n","    x = self.dropout(F.leaky_relu(self.linear1(x))) # clarify why Leaky  (GPT2 uses gelu)\n","    x = self.linear2(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"abjIwp0XtOTg","colab_type":"text"},"source":["## Encoder"]},{"cell_type":"code","metadata":{"id":"GwKhKOK9gsgI","colab_type":"code","colab":{}},"source":["class EncoderLayer(nn.Module):\n","  def __init__(self, emb_dim, heads, dropout = 0.1):\n","    super().__init__()\n","    self.ln1 = LayerNorm(emb_dim)\n","    self.dropout1 = nn.Dropout(dropout)\n","    self.attn = MultiHeadAttention(n_heads = heads, emb_dim = emb_dim, dropout = dropout)\n","    self.ln2 = LayerNorm(emb_dim)\n","    self.ffwd = FeedForward(emb_dim, dropout = dropout)\n","    self.dropout2 = nn.Dropout(dropout)\n","\n","  def forward(self, vector_sequence, mask):\n","    x = self.ln1(vector_sequence)\n","    x_attn, x_scores = self.attn(x, x, x, mask) # (batch_size, seq_len, emb_dim), (batch_size, n_heads, seq_len, seq_len)\n","    vector_sequence = vector_sequence + self.dropout1(x_attn)\n","    x = self.ln2(vector_sequence)\n","    vector_sequence = vector_sequence + self.dropout2(self.ffwd(x)) # ¿CLARIFY USE OF FEEDFORWARD?\n","    return vector_sequence # (batch_size, seq_len, emb_dim)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSwf9Yfxx6M0","colab_type":"code","colab":{}},"source":["class Encoder(nn.Module):\n","  def __init__(self, emb_dim, embedding, n_layers, heads, dropout):\n","    super().__init__()\n","    self.n_layers = n_layers\n","    self.wte = embedding # word token embedding\n","    self.wpe = PositionalEncoder(emb_dim) # word position encoding\n","    self.layers = get_clones(EncoderLayer(emb_dim, heads, dropout = dropout), n_layers)\n","    self. ln = LayerNorm(emb_dim)\n","\n","  def forward(self, source_seq, source_mask):\n","    x = self.wte(source_seq) # [batch_size, seq_len, emb_dim] ¿CLARIFY?\n","    x = x + self.wpe(source_seq) # [batch_size, seq_len, emb_dim] ¿CLARIFY?\n","    for i in range(self.n_layers):\n","      x = self.layers[i](x, source_mask)\n","    x = self.ln(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ITV-M_475-QC","colab_type":"text"},"source":["## Decoder"]},{"cell_type":"code","metadata":{"id":"jxmhpnIc5Ra_","colab_type":"code","colab":{}},"source":["class DecoderLayer(nn.Module):\n","  def __init__(self, emb_dim, heads, dropout = 0.1):\n","    super().__init__()\n","    self.ln1 = LayerNorm(emb_dim)\n","    self.ln2 = LayerNorm(emb_dim)\n","    self.ln3 = LayerNorm(emb_dim)\n","\n","    self.dropout1 = nn.Dropout(dropout)\n","    self.dropout2 = nn.Dropout(dropout)\n","    self.dropout3 = nn.Dropout(dropout)\n","\n","    self.attn1 = MultiHeadAttention(heads, emb_dim, dropout = dropout)\n","    self.attn2 = MultiHeadAttention(heads, emb_dim, dropout = dropout)\n","    self.ffwd = FeedForward(emb_dim, dropout = dropout)\n","\n","  def forward(self, de_out, de_mask, en_out, en_mask):\n","    de_nrm = self.ln1(de_out)\n","    # Self Attention\n","    self_attn, self_scores = self.attn1(de_nrm, de_nrm, de_nrm, de_mask)\n","    de_out = de_out + self.dropout1(self_attn)\n","    de_nrm = self.ln2(de_out)\n","    # Encoder-Decoder Attention\n","    en_attn, en_scores = self.attn2(de_nrm, en_out, en_out, en_mask)\n","    de_out = de_out + self.dropout2(en_attn)\n","    de_nrm = self.ln3(de_out)\n","    de_out = de_out + self.dropout3(self.ffwd(de_nrm))\n","    return de_out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxdc24eM8PFl","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","  def __init__(self, emb_dim, embedding, n_layers, heads, dropout):\n","    super().__init__()\n","    self.n_layers = n_layers\n","    self.wte = embedding\n","    self.wpe = PositionalEncoder(emb_dim)\n","    self.layers = get_clones(DecoderLayer(emb_dim, heads, dropout), n_layers)\n","    self.ln = LayerNorm(emb_dim)\n","\n","  def forward(self, de_toks, de_mask, en_vecs, en_mask):\n","    x = self.wte(de_toks)\n","    x = x + self.wpe(de_toks)\n","    for i in range(self.n_layers):\n","      x = self.layers[i](x, de_mask, en_vecs, en_mask)\n","    return self.ln(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zHk0ltHmm97M","colab_type":"text"},"source":["## Transformer"]},{"cell_type":"code","metadata":{"id":"DjTQgHBSIlbw","colab_type":"code","colab":{}},"source":["class Transformer(nn.Module):\n","  def __init__(self, vocab_size, emb_dim, embedding, n_layers, heads, dropout):\n","    super().__init__()\n","    self.encoder = Encoder(emb_dim, embedding, n_layers, heads, dropout)\n","    self.decoder = Decoder(emb_dim, embedding, n_layers, heads, dropout)\n","    self.out = nn.Linear(emb_dim, vocab_size)\n","\n","  def forward(self, src_seq, trg_seq, src_mask, trg_mask):\n","    e_output = self.encoder(src_seq, src_mask)\n","    d_output = self.decoder(trg_seq, trg_mask, e_output, src_mask)\n","    output = self.out(d_output)\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b8IqscCKqVTw","colab_type":"text"},"source":["# Train"]},{"cell_type":"markdown","metadata":{"id":"4G_zR8vf7kea","colab_type":"text"},"source":["Define train parameters for Transformer_2: embd_dim = 512, n_layers = 12, heads = 12, lr = 0.0001"]},{"cell_type":"code","metadata":{"id":"g4WXY-ugtJIV","colab_type":"code","colab":{}},"source":["#Experiment name:\n","xp_name = 'Transformer_2'\n","# Pretrained models at:\n","wd = '/content/drive/My Drive/706/checkpoints'\n","folder_name = os.path.join(wd, xp_name)\n","\n","# Get device right\n","device = 'cpu'\n","if (torch.cuda.is_available()):\n","    device = torch.device('cuda')\n","\n","epoch = 0\n","\n","# DataLoader\n","batch_size = 1\n","ds = dataset_vf1.dataset(voc, pairs)\n","dataloader = data.DataLoader(ds, batch_size = batch_size, shuffle = False)\n","\n","# Transformer params:\n","emb_dim = 512\n","n_layers = 12\n","heads = 12\n","dropout = 0.01\n","lr = 0.0001\n","lr_str = '0001'\n","\n","# Instantiate embedding, model, optimizer and scheduler\n","embedding = nn.Embedding(voc.num_words, emb_dim)\n","model = Transformer(vocab_size = voc.num_words, emb_dim = emb_dim, embedding = embedding, n_layers = n_layers, heads = heads, dropout = dropout)\n","# Get model to device\n","model.to(device)\n","optimizer = optim.Adam(model.parameters(), lr = lr)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5)\n","\n","# Have a pre-trained model? If so set pretrained to True and load:\n","pretrained = True\n","if pretrained:\n","  try:\n","    checkpoint = torch.load(os.path.join(folder_name, 'checkpoint.pth'))\n","  except:\n","    raise FileNotFoundError(\"Unable to load checkpoint\")\n","  epoch = checkpoint['epoch'] + 1\n","  optimizer.load_state_dict(checkpoint['optimizer'])\n","  try:\n","    params = torch.load(os.path.join(folder_name, xp_name + '_lr' + lr_str + '_bs' + str(batch_size) + '_ed' + str(emb_dim) + '_nl' + str(n_layers) + '_h' + str(heads) + '_epoch' + str(epoch - 1) + '.pth'))\n","  except:\n","    raise FileNotFoundError(\"Unable to load pretrained parameters\")\n","  model.load_state_dict(params)\n","  try:\n","    pre_embedding = torch.load(os.path.join(folder_name, 'embedding.pth'))\n","  except:\n","    raise FileNotFoundError(\"Unable to load pretrained embedding\")\n","  embedding.load_state_dict(pre_embedding)\n","\n","# Get model to device\n","model.to(device)\n","\n","# Loss\n","loss = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-dwLD54RWFH9","colab_type":"text"},"source":["Train loop"]},{"cell_type":"code","metadata":{"id":"xqSkKjJrsait","colab_type":"code","colab":{}},"source":["tb = SummaryWriter()\n","\n","epochs = epoch + 100\n","\n","for e in range(epoch, epochs):\n","\ttotal_loss = 0\n","\tfor batch in dataloader:\n","\t\toptimizer.zero_grad()\n","\t\t# Get inputs and targets and get them into proper device\n","\t\t_, inputs, _, targets, _, _ = batch\n","\t\tinputs, targets = inputs.to(device), targets.to(device)\n","\t\t# Get masks\n","\t\tinput_mask, target_mask = create_masks(inputs, targets, device)\n","\n","\t\t# Get predictions\n","\t\tpreds = model(inputs, targets, input_mask, target_mask)\n","\t\n","\t\t# Compute loss, perform gradient descent and update params\n","\t\tys = targets[:, :].contiguous().view(-1)\n","\t\tbatch_loss = F.cross_entropy(preds.view(-1, preds.size(-1)), ys)\n","\t\tbatch_loss.backward()\n","\t\toptimizer.step()\n","\n","\t\ttotal_loss += batch_loss.item()\n","\n","\tepoch_loss = total_loss / (len(dataloader))\n","\tscheduler.step(epoch_loss)\n","\n","\ttb.add_scalar('Total Loss', total_loss, e)\n","\ttb.add_scalar('Epoch Loss', epoch_loss, e)\n","\tprint('full batch')\n","\tif e % 1 == 0:\n","\t\ttorch.save({'epoch': e, 'optimizer': optimizer.state_dict()},\n","\t\t\t\t   os.path.join(folder_name, 'checkpoint.pth'))\n","\t\ttorch.save(model.state_dict(),\n","\t\t\t\t   os.path.join(folder_name, xp_name + 'lr' + lr_str + '_bs' + str(batch_size) + '_ed' + str(emb_dim)\n","\t\t\t\t\t\t\t\t+ '_nl' + str(n_layers) + '_h' + str(heads) + '_epoch' + str(e) + '.pth'))\n","\t\ttorch.save(embedding.state_dict(), os.path.join(folder_name, 'embedding.pth'))\n","\n","tb.close()\n","\n","torch.save({'epoch': e, 'optimizer': optimizer.state_dict()},\n","\t\t   os.path.join(folder_name, 'checkpoint.pth'))\n","torch.save(model.state_dict(),\n","\t\t   os.path.join(folder_name, xp_name + 'lr' + lr_str + '_bs' + str(batch_size) + '_ed' + str(emb_dim)\n","\t\t\t\t\t\t+ '_nl' + str(n_layers) + '_h' + str(heads) + '_epoch' + str(e) + '.pth'))\n","torch.save(embedding.state_dict(), os.path.join(folder_name, 'embedding.pth'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OqSYRsngIb1f","colab_type":"text"},"source":["# Chat!"]},{"cell_type":"markdown","metadata":{"id":"0aTxF4jjJDJt","colab_type":"text"},"source":["Set up chat"]},{"cell_type":"code","metadata":{"id":"LuVFcLlGpkww","colab_type":"code","colab":{}},"source":["PAD_token = 0\n","SOS_token = 1\n","EOS_token = 2\n","\n","def unicodeToAscii(s):\n","\treturn ''.join(\n","\t\tc for c in unicodedata.normalize('NFD', s)\n","\t\tif unicodedata.category(c) != 'Mn'\n","\t)\n"," \n","def normalizeString(s):\n","\ts = unicodeToAscii(s.lower().strip())\n","\ts = re.sub(r\"([.!?])\", r\" \\1\", s)\n","\ts = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","\ts = re.sub(r\"\\s+\", r\" \", s).strip()\n","\treturn s\n","\n","def talk(input_sentence, model, voc):\n","  model.eval()\n","  model.to(device)\n","  \n","  tokenized = list([SOS_token] + [voc.word2index[word] for word in input_sentence.split(' ')] + [EOS_token])\n","  while len(tokenized) < 22: tokenized.append(PAD_token)\n","  tokenized = [tokenized]\n","  input_sequence = torch.LongTensor(tokenized)\n","  input_sequence = input_sequence.to(device)\n","  \n","  # make input mask\n","  input_mask = (input_sequence != PAD_token).unsqueeze(-2)\n","  input_mask = input_mask.to(device)\n","\n","  encoding = model.encoder(input_sequence, input_mask)\n","  decoder_input = torch.LongTensor([[SOS_token]])\n","  decoder_input = decoder_input.to(device)\n","\n","  for pos in range(22):\n","    decoder_input_mask = nopeak_mask(size=pos+1) # make target mask\n","    decoder_input_mask = decoder_input_mask.to(device)\n","    # the out vector contains the logits that are rebalanced by the softmax\n","    out = model.out(model.decoder(decoder_input, decoder_input_mask, encoding, input_mask))\n","    # softout is a categorical probability distribution over the output vocab\n","    softout = F.softmax(out, dim = -1)\n","    distr = Categorical(probs=softout)\n","    # sample from that distribution to get next token\n","    action = distr.sample()[:, -1].unsqueeze(0)\n","\n","    # concatenate that token to our running list of output tokens \n","    decoder_input = torch.cat((decoder_input, action), dim = 1)\n","\n","    if action == EOS_token:\n","      #answer = ''.join([voc.index2word[token.item()] for token in decoder_input[0]])\n","      answer = [voc.index2word[token.item()] for token in decoder_input[0]]\n","      return answer\n","  #answer = ' '.join([voc.index2word[token.item()] for token in decoder_input[0]])\n","  answer = [voc.index2word[token.item()] for token in decoder_input[0]]\n","  return answer\n","\n","\n","def evaluateInput(model, voc):\n","    input_sentence = ''\n","    while(1):\n","        try:\n","            # Obtenim frase d'input\n","            input_sentence = input('> ')\n","            # Comprovem si finalitza el programa\n","            if input_sentence == 'q' or input_sentence == 'quit': break\n","            # Normalitzem frase\n","            input_sentence = normalizeString(input_sentence)\n","            # Evaluem frase\n","            output_words = talk(input_sentence, model, voc)\n","            # Formatejem i responem\n","            output_words = [x for x in output_words if not (x == 'SOS' or x == 'EOS' or x == 'PAD')]\n","            print('Bot:', ' '.join(output_words))\n","            #print('Bot:', output_words)\n","\n","        except KeyError:\n","            print(\"Error: Encountered unknown word.\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QjjkSx3IJHIt","colab_type":"text"},"source":["Run to start chatting (enter 'q' or 'quit' to quit chat)"]},{"cell_type":"code","metadata":{"id":"Sho0vNDJGwYw","colab_type":"code","outputId":"c5b6b898-c6a0-40a7-dcd0-7dcbc11dfb43","executionInfo":{"status":"ok","timestamp":1590314656474,"user_tz":-120,"elapsed":48716,"user":{"displayName":"CK XZ","photoUrl":"","userId":"14905850197231417667"}},"colab":{"base_uri":"https://localhost:8080/","height":243}},"source":["evaluateInput(model, voc)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["> Hi\n","Bot: translates rank silver silver silver silver silver silver silver silver silver silver silver silver silver\n","> What?\n","Bot: rumours rumours rumours rumours rumours rumours rumours rumours rumours rumours rumours rumours rumours rumours rumours rumours rumours rumours rumours rumours\n","> That makes not much sense..\n","Bot: ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n","> Yes, that's what I say\n","Bot: and and and and and and and and and and and and and and and and and and and and and\n","> Wow\n","Bot: passed passed passed passed passed passed passed drinking drinking drinking drinking drinking drinking drinking drinking drinking drinking drinking drinking drinking\n","> You make no sense!\n","Bot: hurricane medicine medicine medicine medicine medicine medicine medicine medicine medicine medicine medicine medicine violinist violinist violinist violinist violinist violinist contact\n","> q\n"],"name":"stdout"}]}]}